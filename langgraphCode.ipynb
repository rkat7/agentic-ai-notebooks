{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrOUrwUTsEN9Gf2+KvKdz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkat7/agentic-ai-notebooks/blob/main/langgraphCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is LangGraph different from LangChain ?\n",
        "LangChain provides a standard interface to interact with models and other components, useful for retrieval, LLM calls and tools calls. The classes from LangChain might be used in LangGraph, but do not HAVE to be used.\n",
        "\n",
        "The packages are different and can be used in isolation, but, in the end, all resources you will find online use both packages hand in hand.\n",
        "\n",
        "## LangGraph is particularly great when you need control over your application's flow.\n",
        "\n",
        "If your application involves a series of steps that need to be orchestrated in a specific way, with decisions being made at each junction point, LangGraph provides the structure you need.\n",
        "\n",
        "The key scenarios where LangGraph excels include:\n",
        "\n",
        "* Multi-step reasoning processes that need explicit control on the flow\n",
        "* Applications requiring persistence of state between steps\n",
        "* Systems that combine deterministic logic with AI capabilities\n",
        "* Workflows that need human-in-the-loop interventions\n",
        "* Complex agent architectures with multiple components working together"
      ],
      "metadata": {
        "id": "Pk-q476cXv60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Read incoming emails\n",
        "- Classify them as spam or legitimate\n",
        "- Draft a preliminary response for legitimate emails\n",
        "- Send information to Mr. Wayne when legitimate (printing only)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fS25PhAUXztQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langgraph langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ISNqK7bdNFC",
        "outputId": "d60820cd-9e00-4039-a720-458c122f95ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.75)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain_openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "trj5uyLadrOa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmailState(TypedDict):\n",
        "    # The email being processed\n",
        "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
        "\n",
        "    # Category of the email (inquiry, complaint, etc.)\n",
        "    email_category: Optional[str]\n",
        "\n",
        "    # Reason why the email was marked as spam\n",
        "    spam_reason: Optional[str]\n",
        "\n",
        "    # Analysis and decisions\n",
        "    is_spam: Optional[bool]\n",
        "\n",
        "    # Response generation\n",
        "    email_draft: Optional[str]\n",
        "\n",
        "    # Processing metadata\n",
        "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis"
      ],
      "metadata": {
        "id": "KupNM1hidrRA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our LLM\n",
        "model = ChatOpenAI(temperature=0)\n",
        "\n",
        "def read_email(state: EmailState):\n",
        "    \"\"\"Agent reads and logs the incoming email\"\"\"\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    # Here we might do some initial preprocessing\n",
        "    print(f\"Agent is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
        "\n",
        "    # No state changes needed here\n",
        "    return {}\n",
        "\n",
        "def classify_email(state: EmailState):\n",
        "    \"\"\"Agent uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    # Prepare our prompt for the LLM\n",
        "    prompt = f\"\"\"\n",
        "    As Agent, analyze this email and determine if it is spam or legitimate.\n",
        "\n",
        "    Email:\n",
        "    From: {email['sender']}\n",
        "    Subject: {email['subject']}\n",
        "    Body: {email['body']}\n",
        "\n",
        "    First, determine if this email is spam. If it is spam, explain why.\n",
        "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
        "    \"\"\"\n",
        "\n",
        "    # Call the LLM\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
        "    response_text = response.content.lower()\n",
        "    is_spam = \"spam\" in response_text and \"not spam\" not in response_text\n",
        "\n",
        "    # Extract a reason if it's spam\n",
        "    spam_reason = None\n",
        "    if is_spam and \"reason:\" in response_text:\n",
        "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
        "\n",
        "    # Determine category if legitimate\n",
        "    email_category = None\n",
        "    if not is_spam:\n",
        "        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]\n",
        "        for category in categories:\n",
        "            if category in response_text:\n",
        "                email_category = category\n",
        "                break\n",
        "\n",
        "    # Update messages for tracking\n",
        "    new_messages = state.get(\"messages\", []) + [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "        {\"role\": \"assistant\", \"content\": response.content}\n",
        "    ]\n",
        "\n",
        "    # Return state updates\n",
        "    return {\n",
        "        \"is_spam\": is_spam,\n",
        "        \"spam_reason\": spam_reason,\n",
        "        \"email_category\": email_category,\n",
        "        \"messages\": new_messages\n",
        "    }\n",
        "\n",
        "def handle_spam(state: EmailState):\n",
        "    \"\"\"Agent discards spam email with a note\"\"\"\n",
        "    print(f\"Agent has marked the email as spam. Reason: {state['spam_reason']}\")\n",
        "    print(\"The email has been moved to the spam folder.\")\n",
        "\n",
        "    # We're done processing this email\n",
        "    return {}\n",
        "\n",
        "def draft_response(state: EmailState):\n",
        "    \"\"\"Agent drafts a preliminary response for legitimate emails\"\"\"\n",
        "    email = state[\"email\"]\n",
        "    category = state[\"email_category\"] or \"general\"\n",
        "\n",
        "    # Prepare our prompt for the LLM\n",
        "    prompt = f\"\"\"\n",
        "    As Agent, draft a polite preliminary response to this email.\n",
        "\n",
        "    Email:\n",
        "    From: {email['sender']}\n",
        "    Subject: {email['subject']}\n",
        "    Body: {email['body']}\n",
        "\n",
        "    This email has been categorized as: {category}\n",
        "\n",
        "    Draft a brief, professional response that can be reviewied and personalized before sending.\n",
        "    \"\"\"\n",
        "\n",
        "    # Call the LLM\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Update messages for tracking\n",
        "    new_messages = state.get(\"messages\", []) + [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "        {\"role\": \"assistant\", \"content\": response.content}\n",
        "    ]\n",
        "\n",
        "    # Return state updates\n",
        "    return {\n",
        "        \"email_draft\": response.content,\n",
        "        \"messages\": new_messages\n",
        "    }\n",
        "\n",
        "def notify_user(state: EmailState):\n",
        "    \"\"\"Agent notifies about the email and presents the draft response\"\"\"\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"You've received an email from {email['sender']}.\")\n",
        "    print(f\"Subject: {email['subject']}\")\n",
        "    print(f\"Category: {state['email_category']}\")\n",
        "    print(\"\\nI've prepared a draft response for your review:\")\n",
        "    print(\"-\"*50)\n",
        "    print(state[\"email_draft\"])\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # We're done processing this email\n",
        "    return {}"
      ],
      "metadata": {
        "id": "i1BHi0ZHdrTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_email(state: EmailState) -> str:\n",
        "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
        "    if state[\"is_spam\"]:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"legitimate\""
      ],
      "metadata": {
        "id": "Dy70XmJfdrV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph\n",
        "email_graph = StateGraph(EmailState)\n",
        "\n",
        "# Add nodes\n",
        "email_graph.add_node(\"read_email\", read_email)\n",
        "email_graph.add_node(\"classify_email\", classify_email)\n",
        "email_graph.add_node(\"handle_spam\", handle_spam)\n",
        "email_graph.add_node(\"draft_response\", draft_response)\n",
        "email_graph.add_node(\"notify_user\", notify_user)\n",
        "\n",
        "# Start the edges\n",
        "email_graph.add_edge(START, \"read_email\")\n",
        "# Add edges - defining the flow\n",
        "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
        "\n",
        "# Add conditional branching from classify_email\n",
        "email_graph.add_conditional_edges(\n",
        "    \"classify_email\",\n",
        "    route_email,\n",
        "    {\n",
        "        \"spam\": \"handle_spam\",\n",
        "        \"legitimate\": \"draft_response\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add the final edges\n",
        "email_graph.add_edge(\"handle_spam\", END)\n",
        "email_graph.add_edge(\"draft_response\", \"notify_user\")\n",
        "email_graph.add_edge(\"notify_user\", END)\n",
        "\n",
        "# Compile the graph\n",
        "compiled_graph = email_graph.compile()"
      ],
      "metadata": {
        "id": "SnZmx5k3et2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example legitimate email\n",
        "legitimate_email = {\n",
        "    \"sender\": \"john.smith@example.com\",\n",
        "    \"subject\": \"Question about your services\",\n",
        "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
        "}\n",
        "\n",
        "# Example spam email\n",
        "spam_email = {\n",
        "    \"sender\": \"winner@lottery-intl.com\",\n",
        "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
        "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
        "}\n",
        "\n",
        "# Process the legitimate email\n",
        "print(\"\\nProcessing legitimate email...\")\n",
        "legitimate_result = compiled_graph.invoke({\n",
        "    \"email\": legitimate_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})\n",
        "\n",
        "# Process the spam email\n",
        "print(\"\\nProcessing spam email...\")\n",
        "spam_result = compiled_graph.invoke({\n",
        "    \"email\": spam_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})"
      ],
      "metadata": {
        "id": "Lnd0BeC2et5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the Mail Sorting Agent with Langfuse"
      ],
      "metadata": {
        "id": "7zi-eo-OfELD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langfuse\n",
        "%pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYusDNKffG8p",
        "outputId": "42615625-315e-4fbf-cec0-cdb0aefb2b57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
        "#os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # üá™üá∫ EU region\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # üá∫üá∏ US region"
      ],
      "metadata": {
        "id": "qQ0cqrIsfM7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# Process legitimate email\n",
        "legitimate_result = compiled_graph.invoke(\n",
        "    input={\"email\": legitimate_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        ")"
      ],
      "metadata": {
        "id": "ksMgriBcgK5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_graph.get_graph().draw_mermaid_png()"
      ],
      "metadata": {
        "id": "nmzhi12PgSJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}